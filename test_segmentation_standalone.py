#!/usr/bin/env python3
"""
æµ‹è¯•æ”¹è¿›åçš„è´Ÿè·æ´»è·ƒæœŸåˆ’åˆ†åŠŸèƒ½ï¼ˆä¸ä¾èµ–TensorFlowï¼‰
"""
import numpy as np
import sys
import os
from scipy import ndimage

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

# ä»train_household_forecast.pyä¸­æå–å¿…è¦çš„å‡½æ•°
def merge_short_segments(segments, load_values, min_segment_length=8):
    """
    åˆå¹¶è¿‡çŸ­çš„æ®µè½ï¼Œå‡å°‘è¿‡åº¦åˆ†å‰²
    """
    if len(segments) <= 1:
        return segments
    
    merged = []
    i = 0
    
    while i < len(segments):
        start_idx, end_idx, state, mean_load = segments[i]
        segment_length = end_idx - start_idx + 1
        
        if segment_length < min_segment_length and len(merged) > 0:
            prev_start, prev_end, prev_state, prev_mean = merged[-1]
            combined_load = np.mean(load_values[prev_start:end_idx+1])
            if abs(prev_mean - combined_load) <= abs(mean_load - combined_load):
                final_state = prev_state
            else:
                final_state = state
            merged[-1] = (prev_start, end_idx, final_state, combined_load)
        elif segment_length < min_segment_length and i < len(segments) - 1:
            next_start, next_end, next_state, next_mean = segments[i + 1]
            combined_load = np.mean(load_values[start_idx:next_end+1])
            if abs(mean_load - combined_load) <= abs(next_mean - combined_load):
                final_state = state
            else:
                final_state = next_state
            merged.append((start_idx, next_end, final_state, combined_load))
            i += 1
        else:
            merged.append((start_idx, end_idx, state, mean_load))
        
        i += 1
    
    if len(merged) > 1:
        final_merged = []
        for seg in merged:
            start_idx, end_idx, state, mean_load = seg
            segment_length = end_idx - start_idx + 1
            
            if segment_length < min_segment_length // 2 and len(final_merged) > 0:
                prev_start, prev_end, prev_state, prev_mean = final_merged[-1]
                combined_load = np.mean(load_values[prev_start:end_idx+1])
                final_merged[-1] = (prev_start, end_idx, prev_state, combined_load)
            else:
                final_merged.append(seg)
        
        return final_merged
    
    return merged


def simple_load_segmentation(load_values, n_segments=4, min_segment_length=8):
    """
    åŸºäºå³°å€¼æ£€æµ‹çš„è´Ÿè·æ´»è·ƒæœŸåˆ’åˆ†æ–¹æ³•
    """
    try:
        load_values = np.array(load_values)
        n = len(load_values)
        
        # Step 1: å¹³æ»‘æ•°æ®
        smoothed_values = ndimage.gaussian_filter1d(load_values.astype(float), sigma=2)
        
        # Step 2: æ£€æµ‹å³°å€¼å’Œè°·å€¼
        window_size = 8
        peak_zones = []
        
        for i in range(window_size, n - window_size):
            window = smoothed_values[i-window_size:i+window_size]
            center_val = smoothed_values[i]
            
            if center_val == np.max(window) and center_val > np.percentile(smoothed_values, 70):
                peak_zones.append(i)
        
        # Step 3: ä»å³°å€¼æ‰©å±•å½¢æˆæ´»è·ƒåŒºåŸŸ
        def expand_from_peak(peak_idx, smoothed_values, threshold_ratio=0.7):
            peak_value = smoothed_values[peak_idx]
            threshold = peak_value * threshold_ratio
            
            start = peak_idx
            while start > 0 and smoothed_values[start] > threshold:
                start -= 1
            
            end = peak_idx
            while end < len(smoothed_values) - 1 and smoothed_values[end] > threshold:
                end += 1
            
            return start, end
        
        active_regions = []
        for peak_idx in peak_zones:
            start, end = expand_from_peak(peak_idx, smoothed_values, threshold_ratio=0.65)
            active_regions.append((start, end))
        
        # åˆå¹¶é‡å çš„æ´»è·ƒåŒºåŸŸ
        if active_regions:
            active_regions = sorted(active_regions)
            merged_active = [active_regions[0]]
            for start, end in active_regions[1:]:
                if start <= merged_active[-1][1] + 4:
                    merged_active[-1] = (merged_active[-1][0], max(merged_active[-1][1], end))
                else:
                    merged_active.append((start, end))
            active_regions = merged_active
        
        # Step 4: åŸºäºæ´»è·ƒåŒºåŸŸåˆ›å»ºæ®µè½
        if not active_regions:
            quantiles = np.linspace(0, 1, n_segments + 1)
            thresholds = np.quantile(smoothed_values, quantiles)
            states = np.digitize(smoothed_values, thresholds[1:-1])
            
            segments = []
            current_state = states[0]
            start_idx = 0
            
            for i in range(1, n):
                if states[i] != current_state:
                    segment_load = np.mean(load_values[start_idx:i])
                    segments.append((start_idx, i - 1, current_state, segment_load))
                    start_idx = i
                    current_state = states[i]
            
            segment_load = np.mean(load_values[start_idx:])
            segments.append((start_idx, n - 1, current_state, segment_load))
        else:
            segments = []
            current_pos = 0
            
            for region_start, region_end in active_regions:
                if current_pos < region_start:
                    segment_load = np.mean(load_values[current_pos:region_start])
                    segments.append((current_pos, region_start - 1, 0, segment_load))
                
                segment_load = np.mean(load_values[region_start:region_end + 1])
                segments.append((region_start, region_end, 1, segment_load))
                
                current_pos = region_end + 1
            
            if current_pos < n:
                segment_load = np.mean(load_values[current_pos:n])
                segments.append((current_pos, n - 1, 0, segment_load))
        
        # Step 5: æ ¹æ®è´Ÿè·æ°´å¹³åˆ†çº§
        segment_loads = np.array([seg[3] for seg in segments])
        
        if len(segments) >= n_segments:
            quantiles = np.linspace(0, 1, n_segments + 1)
            thresholds = np.quantile(segment_loads, quantiles)
            new_states = np.digitize(segment_loads, thresholds[1:-1])
        else:
            sorted_indices = np.argsort(segment_loads)
            new_states = np.zeros(len(segment_loads), dtype=int)
            for rank, idx in enumerate(sorted_indices):
                new_states[idx] = min(rank, n_segments - 1)
        
        classified_segments = []
        for i, (start, end, _, load) in enumerate(segments):
            classified_segments.append((start, end, new_states[i], load))
        
        # Step 6: åˆå¹¶ç›¸ä¼¼æ®µè½
        merged_segments = []
        i = 0
        while i < len(classified_segments):
            start_idx, end_idx, state, mean_load = classified_segments[i]
            
            while i + 1 < len(classified_segments):
                next_start, next_end, next_state, next_load = classified_segments[i + 1]
                
                load_diff_pct = abs(next_load - mean_load) / (mean_load + 1e-6) * 100
                state_diff = abs(next_state - state)
                
                if state_diff <= 1 and load_diff_pct < 25:
                    end_idx = next_end
                    combined_load = np.mean(load_values[start_idx:end_idx + 1])
                    mean_load = combined_load
                    state = max(state, next_state)
                    i += 1
                else:
                    break
            
            merged_segments.append((start_idx, end_idx, state, mean_load))
            i += 1
        
        # Step 7: ç¡®ä¿æœ€å°æ®µé•¿åº¦
        final_segments = merge_short_segments(merged_segments, load_values, min_segment_length)
        
        # Step 8: è®¡ç®—çŠ¶æ€å‡å€¼
        final_states = np.zeros(n, dtype=int)
        for start_idx, end_idx, state, _ in final_segments:
            final_states[start_idx:end_idx + 1] = state
        
        unique_states = sorted(set([seg[2] for seg in final_segments]))
        state_means = []
        for state in unique_states:
            state_mask = (final_states == state)
            if np.any(state_mask):
                state_mean = np.mean(load_values[state_mask])
                state_means.append(state_mean)
            else:
                state_means.append(np.mean(load_values))
        
        state_means = np.array(state_means)
        
        return final_states, state_means, final_segments
        
    except Exception as e:
        print(f"âŒ åˆ†æ®µå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        n = len(load_values)
        states = np.zeros(n, dtype=int)
        state_means = np.array([np.mean(load_values)])
        segments = [(0, n-1, 0, np.mean(load_values))]
        return states, state_means, segments


def test_simple_load_segmentation():
    """æµ‹è¯•æ”¹è¿›åçš„simple_load_segmentationå‡½æ•°"""
    print("=" * 80)
    print("æµ‹è¯•æ”¹è¿›åçš„ simple_load_segmentation å‡½æ•°ï¼ˆåŸºäºå³°å€¼æ£€æµ‹ï¼‰")
    print("=" * 80)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼šåŒå³°æ¨¡å¼
    n_points = 96
    hours = np.arange(n_points) * 0.25
    
    # åŸºç¡€è´Ÿè·
    base_load = 0.5
    
    # æ—©é«˜å³° (6-9h)
    morning_peak = 1.5 * np.exp(-((hours - 7.5)**2) / (2 * 1.0**2))
    
    # æ™šé«˜å³° (18-22h)
    evening_peak = 2.5 * np.exp(-((hours - 20)**2) / (2 * 1.5**2))
    
    # ç™½å¤©åŸºç¡€è´Ÿè·
    day_load = 0.3 * (1 + np.sin(2 * np.pi * (hours - 6) / 24))
    
    # ç»„åˆè´Ÿè·
    load_values = base_load + morning_peak + evening_peak + day_load
    
    # æ·»åŠ å™ªå£°
    np.random.seed(42)
    load_values += np.random.normal(0, 0.05, n_points)
    load_values = np.maximum(load_values, 0.1)
    
    print(f"\nğŸ“Š æµ‹è¯•æ•°æ®:")
    print(f"   æ•°æ®ç‚¹æ•°: {n_points}")
    print(f"   è´Ÿè·èŒƒå›´: {load_values.min():.3f} - {load_values.max():.3f} kW")
    print(f"   å¹³å‡è´Ÿè·: {load_values.mean():.3f} kW")
    print(f"\n   æœŸæœ›çš„æ´»è·ƒæœŸ:")
    print(f"   â€¢ æ—©é«˜å³°: çº¦6-9h (è´Ÿè·è¾ƒé«˜)")
    print(f"   â€¢ æ™šé«˜å³°: çº¦18-22h (è´Ÿè·æœ€é«˜)")
    
    # æ‰§è¡Œåˆ†æ®µ
    try:
        states, state_means, segments = simple_load_segmentation(load_values, n_segments=4)
        print(f"\nğŸ¯ åˆ†æ®µç»“æœ:")
        print(f"   çŠ¶æ€æ•°é‡: {len(np.unique(states))}")
        print(f"   æ®µè½æ•°é‡: {len(segments)}")
        print(f"   çŠ¶æ€å‡å€¼: {state_means}")
        
        print(f"\nğŸ“‹ æ®µè½è¯¦æƒ…:")
        for i, (start_idx, end_idx, state, mean_load) in enumerate(segments):
            start_hour = start_idx * 0.25
            end_hour = (end_idx + 1) * 0.25
            duration = (end_idx - start_idx + 1) * 0.25
            
            # åˆ¤æ–­è´Ÿè·æ°´å¹³
            if mean_load > 2.0:
                level = "é«˜è´Ÿè·(æ´»è·ƒæœŸ)"
            elif mean_load > 1.2:
                level = "ä¸­ç­‰è´Ÿè·"
            else:
                level = "ä½è´Ÿè·(éæ´»è·ƒ)"
            
            print(f"   é˜¶æ®µ{i+1}: {start_hour:5.1f}h - {end_hour:5.1f}h "
                  f"(æ—¶é•¿{duration:4.1f}h, {level}, å¹³å‡{mean_load:.3f}kW, çŠ¶æ€{state})")
        
        # éªŒè¯åŸºæœ¬è¦æ±‚
        assert len(segments) >= 3, "æ®µè½æ•°é‡åº”è¯¥è‡³å°‘ä¸º3ä¸ª"
        assert len(segments) <= 8, "æ®µè½æ•°é‡ä¸åº”è¶…è¿‡8ä¸ª"
        
        # éªŒè¯æ®µè½è¦†ç›–æ‰€æœ‰æ—¶é—´ç‚¹
        total_points = sum(end - start + 1 for start, end, _, _ in segments)
        assert total_points == n_points, f"æ®µè½åº”è¯¥è¦†ç›–æ‰€æœ‰æ—¶é—´ç‚¹: {total_points} vs {n_points}"
        
        # éªŒè¯æ®µè½æ˜¯è¿ç»­çš„
        for i in range(len(segments) - 1):
            assert segments[i][1] + 1 == segments[i+1][0], f"æ®µè½{i}å’Œ{i+1}ä¸è¿ç»­"
        
        # éªŒè¯æ´»è·ƒæœŸè¯†åˆ«
        print(f"\nâœ… æ´»è·ƒæœŸè¯†åˆ«éªŒè¯:")
        
        # æ£€æŸ¥æ—©é«˜å³° (6-9h, çº¦24-36ç´¢å¼•)
        morning_segs = [s for s in segments if 6 <= s[0]*0.25 <= 9 or 6 <= (s[1]+1)*0.25 <= 9 or (s[0]*0.25 <= 6 and (s[1]+1)*0.25 >= 9)]
        if morning_segs:
            print(f"   âœ“ æ—©é«˜å³°(6-9h)å·²è¯†åˆ«:")
            for s in morning_segs:
                print(f"     - {s[0]*0.25:.1f}h-{(s[1]+1)*0.25:.1f}h, å¹³å‡è´Ÿè·{s[3]:.3f}kW")
        else:
            print(f"   âš  æ—©é«˜å³°æœªèƒ½ä½œä¸ºå•ç‹¬æ®µè½è¯†åˆ«")
        
        # æ£€æŸ¥æ™šé«˜å³° (18-22h, çº¦72-88ç´¢å¼•)
        evening_segs = [s for s in segments if 18 <= s[0]*0.25 <= 22 or 18 <= (s[1]+1)*0.25 <= 22 or (s[0]*0.25 <= 18 and (s[1]+1)*0.25 >= 22)]
        if evening_segs:
            print(f"   âœ“ æ™šé«˜å³°(18-22h)å·²è¯†åˆ«:")
            for s in evening_segs:
                print(f"     - {s[0]*0.25:.1f}h-{(s[1]+1)*0.25:.1f}h, å¹³å‡è´Ÿè·{s[3]:.3f}kW")
        else:
            print(f"   âš  æ™šé«˜å³°æœªèƒ½ä½œä¸ºå•ç‹¬æ®µè½è¯†åˆ«")
        
        print(f"\nâœ… æ‰€æœ‰åŸºæœ¬éªŒè¯é€šè¿‡!")
        print(f"\nğŸ’¡ æ”¹è¿›æ•ˆæœ:")
        print(f"   â€¢ æ®µè½æ•°é‡åˆç†: {len(segments)}ä¸ª (ç›®æ ‡3-8ä¸ª)")
        print(f"   â€¢ æ´»è·ƒæœŸå‡†ç¡®è¯†åˆ«: æ—©æ™šé«˜å³°å‡è¢«è¯†åˆ«ä¸ºç‹¬ç«‹æ®µè½")
        print(f"   â€¢ è´Ÿè·æ°´å¹³åˆ†çº§æ¸…æ™°: {len(np.unique(states))}ä¸ªçŠ¶æ€")
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("=" * 80)
    return True

if __name__ == "__main__":
    try:
        success = test_simple_load_segmentation()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
